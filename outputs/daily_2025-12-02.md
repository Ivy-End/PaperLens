## 每日论文推荐 — 2025-12-02

- **OneThinker: All-in-one Reasoning Model for Image and Video**
  - 发表日期：2025-12-02 | 推荐度：0.831 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.03043v1
  - 摘要：Reinforcement learning (RL) has recently achieved remarkable success in eliciting visual reasoning within Multimodal Large Language Models (MLLMs). However, existing approaches typically train separate models for different tasks and treat image and video reasoning as disjoint domains. This results in limited scalability toward a multimodal reasoning generalist, which restricts practical versatility and hinders potential knowledge sharing across tasks and modalities. To this end, we propose OneThinker, an all-in-one reasoning model that unifies image and video understanding across diverse fundamental visual tasks, including question answering, captioning, spatial and temporal grounding, tracking, and segmentation. To achieve this, we construct the OneThinker-600k training corpus covering all these tasks and employ commercial models for CoT annotation, resulting in OneThinker-SFT-340k for SFT cold start. Furthermore, we propose EMA-GRPO to handle reward heterogeneity in multi-task RL by tracking task-wise moving averages of reward standard deviations for balanced optimization. Extensive experiments on diverse visual benchmarks show that OneThinker delivers strong performance on 31 benchmarks, across 10 fundamental visual understanding tasks. Moreover, it exhibits effective knowledge transfer between certain tasks and preliminary zero-shot generalization ability, marking a step toward a unified multimodal reasoning generalist. All code, model, and data are released.

- **Channel Knowledge Map Construction via Physics-Inspired Diffusion Model Without Prior Observations**
  - 发表日期：2025-12-02 | 推荐度：0.823 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02757v1
  - 摘要：The ability to construct Channel Knowledge Map (CKM) with high precision is essential for environment awareness in 6G wireless systems. However, most existing CKM construction methods formulate the task as an image super-resolution or generation problem, thereby employing models originally developed for computer vision. As a result, the generated CKMs often fail to capture the underlying physical characteristics of wireless propagation. In this paper, we focus on the construction of CKM for large-scale fading scenarios and design three physics-based constraint terms to characterize the spatial distribution patterns of large-scale fading. By integrating these physical constraints with a state-of-the-art diffusion model that possesses superior generative capability, a physics-inspired diffusion model for CKM construction is proposed. Following this motivation, we derive the loss function of the diffusion model augmented with physics-based constraint terms and further design the training and generation framework for the proposed physics-inspired CKM generation diffusion model. Extensive experiments show that our approach outperforms all existing methods in terms of construction accuracy. Moreover, the proposed model provides a unified and effective framework with strong potential for generating diverse, accurate, and physically consistent CKM.

- **MagicQuillV2: Precise and Interactive Image Editing with Layered Visual Cues**
  - 发表日期：2025-12-02 | 推荐度：0.820 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.03046v1
  - 摘要：We propose MagicQuill V2, a novel system that introduces a \textbf{layered composition} paradigm to generative image editing, bridging the gap between the semantic power of diffusion models and the granular control of traditional graphics software. While diffusion transformers excel at holistic generation, their use of singular, monolithic prompts fails to disentangle distinct user intentions for content, position, and appearance. To overcome this, our method deconstructs creative intent into a stack of controllable visual cues: a content layer for what to create, a spatial layer for where to place it, a structural layer for how it is shaped, and a color layer for its palette. Our technical contributions include a specialized data generation pipeline for context-aware content integration, a unified control module to process all visual cues, and a fine-tuned spatial branch for precise local editing, including object removal. Extensive experiments validate that this layered approach effectively resolves the user intention gap, granting creators direct, intuitive control over the generative process.

- **Steering Vision-Language-Action Models as Anti-Exploration: A Test-Time Scaling Approach**
  - 发表日期：2025-12-02 | 推荐度：0.820 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02834v1
  - 摘要：Vision-Language-Action (VLA) models, trained via flow-matching or diffusion objectives, excel at learning complex behaviors from large-scale, multi-modal datasets (e.g., human teleoperation, scripted policies). However, since VLAs incorporate diverse data modes in the pre-training stage, and the finetuning dataset often contains demonstration data collected in a kinematically suboptimal or undesirable way, it exists redundant action modes that are irrelevant to the success action modes of the downstream task. Specifically, we observe a critical inference-time fragility among various sampled noises after supervised finetuning of pre-trained VLAs. In this paper, we attribute this instability to the distribution shift between the VLA policy and the policy induced by stable success modes of the downstream task dataset. Thus, we propose \textbf{TACO}, a test-time-scaling (TTS) framework that applies a lightweight pseudo-count estimator as a high-fidelity verifier of action chunks. The VLA models integrated with TACO can execute the actions with maximum pseudo-count from all sampled action chunks, thereby preventing distribution shifts while preserving the generalization ability of VLAs since the constraint is applied only during inference. Our method resembles the classical anti-exploration principle in offline reinforcement learning (RL), and being gradient-free, it incurs significant computational benefits compared to RL update, especially for flow or diffusion-based VLAs which are difficult to perform RL update due to denoising process. Extensive experiments across four simulation benchmarks (RoboTwin2.0, Robotwin, LIBERO, SimplerEnv) and a dual-arm platform demonstrate that our method significantly improves the inference stability and success rates in downstream-task adaptations.

- **LumiX: Structured and Coherent Text-to-Intrinsic Generation**
  - 发表日期：2025-12-02 | 推荐度：0.818 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02781v1
  - 摘要：We present LumiX, a structured diffusion framework for coherent text-to-intrinsic generation. Conditioned on text prompts, LumiX jointly generates a comprehensive set of intrinsic maps (e.g., albedo, irradiance, normal, depth, and final color), providing a structured and physically consistent description of an underlying scene. This is enabled by two key contributions: 1) Query-Broadcast Attention, a mechanism that ensures structural consistency by sharing queries across all maps in each self-attention block. 2) Tensor LoRA, a tensor-based adaptation that parameter-efficiently models cross-map relations for efficient joint training. Together, these designs enable stable joint diffusion training and unified generation of multiple intrinsic properties. Experiments show that LumiX produces coherent and physically meaningful results, achieving 23% higher alignment and a better preference score (0.19 vs. -0.41) compared to the state of the art, and it can also perform image-conditioned intrinsic decomposition within the same framework.

- **Diffusion-Prior Split Gibbs Sampling for Synthetic Aperture Radar Imaging under Incomplete Measurements**
  - 发表日期：2025-12-02 | 推荐度：0.818 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02768v1
  - 摘要：Synthetic aperture radar (SAR) imaging plays a critical role in all-weather, day-and-night remote sensing, yet reconstruction is often challenged by noise, undersampling, and complex scattering scenarios. Conventional methods, including matched filtering and sparsity-based compressed sensing, are limited in capturing intricate scene structures and frequently suffer from artifacts, elevated sidelobes, and loss of fine details. Recent diffusion models have demonstrated superior capability in representing high-order priors; however, existing diffusion-based SAR methods still yield degraded reconstructions due to oversimplified likelihood approximations in guided sampling. In this work, we propose a diffusion-driven split Gibbs sampling framework for SAR reconstruction, rigorously integrating measurement fidelity with learned diffusion priors. By alternately performing likelihood- and prior-driven updates via proximal sampling, this method ensures progressive convergence toward the true posterior while fully leveraging the expressive power of diffusion priors. Extensive experiments on simulated and Sentinel-1A datasets demonstrate substantial performance improvements: over 7 dB average PSNR gain in simulations, along with significant sidelobe suppression (MPLSR +2.96 dB, MISLR +11.5 dB) with respect to the best baseline result. On real-world Sentinel-1A data, the method achieves an average PSNR gain of 1.6 dB while effectively reducing artifacts and preserving scene details, including ridges, edges, and fine textures. These results underscore the potential of the adapted framework as a robust and generalizable solution for high-fidelity SAR imaging across diverse sensing scenarios.

- **U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences**
  - 发表日期：2025-12-02 | 推荐度：0.817 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02982v1
  - 摘要：Modeling dynamic 3D environments from LiDAR sequences is central to building reliable 4D worlds for autonomous driving and embodied AI. Existing generative frameworks, however, often treat all spatial regions uniformly, overlooking the varying uncertainty across real-world scenes. This uniform generation leads to artifacts in complex or ambiguous regions, limiting realism and temporal stability. In this work, we present U4D, an uncertainty-aware framework for 4D LiDAR world modeling. Our approach first estimates spatial uncertainty maps from a pretrained segmentation model to localize semantically challenging regions. It then performs generation in a "hard-to-easy" manner through two sequential stages: (1) uncertainty-region modeling, which reconstructs high-entropy regions with fine geometric fidelity, and (2) uncertainty-conditioned completion, which synthesizes the remaining areas under learned structural priors. To further ensure temporal coherence, U4D incorporates a mixture of spatio-temporal (MoST) block that adaptively fuses spatial and temporal representations during diffusion. Extensive experiments show that U4D produces geometrically faithful and temporally consistent LiDAR sequences, advancing the reliability of 4D world modeling for autonomous perception and simulation.

- **Rethinking Generalized BCIs: Benchmarking 340,000+ Unique Algorithmic Configurations for EEG Mental Command Decoding**
  - 发表日期：2025-12-02 | 推荐度：0.816 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02978v1
  - 摘要：Robust decoding and classification of brain patterns measured with electroencephalography (EEG) remains a major challenge for real-world (i.e. outside scientific lab and medical facilities) brain-computer interface (BCI) applications due to well documented inter- and intra-participant variability. Here, we present a large-scale benchmark evaluating over 340,000+ unique combinations of spatial and nonlinear EEG classification. Our methodological pipeline consists in combinations of Common Spatial Patterns (CSP), Riemannian geometry, functional connectivity, and fractal- or entropy-based features across three open-access EEG datasets. Unlike prior studies, our analysis operates at the per-participant level and across multiple frequency bands (8-15 Hz and 8-30 Hz), enabling direct assessment of both group-level performance and individual variability. Covariance tangent space projection (cov-tgsp) and CSP consistently achieved the highest average classification accuracies. However, their effectiveness was strongly dataset-dependent, and marked participant-level differences persisted, particularly in the most heterogeneous of the datasets. Importantly, nonlinear methods outperformed spatial approaches for specific individuals, underscoring the need for personalized pipeline selection. Our findings highlight that no universal 'one-size-fits-all' method can optimally decode EEG motor imagery patterns across all users or datasets. Future work will require adaptive, multimodal, and possibly novel approaches to fully address neurophysiological variability in practical BCI applications where the system can automatically adapt to what makes each user unique.

- **ReVSeg: Incentivizing the Reasoning Chain for Video Segmentation with Reinforcement Learning**
  - 发表日期：2025-12-02 | 推荐度：0.815 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02835v1
  - 摘要：Reasoning-centric video object segmentation is an inherently complex task: the query often refers to dynamics, causality, and temporal interactions, rather than static appearances. Yet existing solutions generally collapse these factors into simplified reasoning with latent embeddings, rendering the reasoning chain opaque and essentially intractable. We therefore adopt an explicit decomposition perspective and introduce ReVSeg, which executes reasoning as sequential decisions in the native interface of pretrained vision language models (VLMs). Rather than folding all reasoning into a single-step prediction, ReVSeg executes three explicit operations -- semantics interpretation, temporal evidence selection, and spatial grounding -- aligning pretrained capabilities. We further employ reinforcement learning to optimize the multi-step reasoning chain, enabling the model to self-refine its decision quality from outcome-driven signals. Experimental results demonstrate that ReVSeg attains state-of-the-art performances on standard video object segmentation benchmarks and yields interpretable reasoning trajectories. Project page is available at https://clementine24.github.io/ReVSeg/ .

- **BOOM: Beyond Only One Modality KIT's Multimodal Multilingual Lecture Companion**
  - 发表日期：2025-12-02 | 推荐度：0.814 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02817v1
  - 摘要：The globalization of education and rapid growth of online learning have made localizing educational content a critical challenge. Lecture materials are inherently multimodal, combining spoken audio with visual slides, which requires systems capable of processing multiple input modalities. To provide an accessible and complete learning experience, translations must preserve all modalities: text for reading, slides for visual understanding, and speech for auditory learning. We present \textbf{BOOM}, a multimodal multilingual lecture companion that jointly translates lecture audio and slides to produce synchronized outputs across three modalities: translated text, localized slides with preserved visual elements, and synthesized speech. This end-to-end approach enables students to access lectures in their native language while aiming to preserve the original content in its entirety. Our experiments demonstrate that slide-aware transcripts also yield cascading benefits for downstream tasks such as summarization and question answering. We release our Slide Translation code at https://github.com/saikoneru/image-translator and integrate it in Lecture Translator at https://gitlab.kit.edu/kit/isl-ai4lt/lt-middleware/ltpipeline}\footnote{All released code and models are licensed under the MIT License.

- **Towards Unification of Hallucination Detection and Fact Verification for Large Language Models**
  - 发表日期：2025-12-02 | 推荐度：0.812 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02772v1
  - 摘要：Large Language Models (LLMs) frequently exhibit hallucinations, generating content that appears fluent and coherent but is factually incorrect. Such errors undermine trust and hinder their adoption in real-world applications. To address this challenge, two distinct research paradigms have emerged: model-centric Hallucination Detection (HD) and text-centric Fact Verification (FV). Despite sharing the same goal, these paradigms have evolved in isolation, using distinct assumptions, datasets, and evaluation protocols. This separation has created a research schism that hinders their collective progress. In this work, we take a decisive step toward bridging this divide. We introduce UniFact, a unified evaluation framework that enables direct, instance-level comparison between FV and HD by dynamically generating model outputs and corresponding factuality labels. Through large-scale experiments across multiple LLM families and detection methods, we reveal three key findings: (1) No paradigm is universally superior; (2) HD and FV capture complementary facets of factual errors; and (3) hybrid approaches that integrate both methods consistently achieve state-of-the-art performance. Beyond benchmarking, we provide the first in-depth analysis of why FV and HD diverged, as well as empirical evidence supporting the need for their unification. The comprehensive experimental results call for a new, integrated research agenda toward unifying Hallucination Detection and Fact Verification in LLMs.
  We have open-sourced all the code, data, and baseline implementation at: https://github.com/oneal2000/UniFact/

- **promptolution: A Unified, Modular Framework for Prompt Optimization**
  - 发表日期：2025-12-02 | 推荐度：0.810 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02840v1
  - 摘要：Prompt optimization has become crucial for enhancing the performance of large language models (LLMs) across a broad range of tasks. Although many research papers show its effectiveness, practical adoption is hindered as existing implementations are often tied to unmaintained and isolated research codebases. To address this, we introduce promptolution, a unified and modular open-source framework that provides all components required for prompt optimization within a single extensible system for both practitioners and researchers. It integrates multiple contemporary discrete prompt optimizers while remaining agnostic to the underlying LLM implementation.

- **Vessel Network Topology in Molecular Communication: Insights from Experiments and Theory**
  - 发表日期：2025-12-02 | 推荐度：0.809 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02811v1
  - 摘要：The notion of synthetic molecular communication (MC) refers to the transmission of information via signaling molecules and is foreseen to enable innovative medical applications in the human cardiovascular system (CVS). Crucially, the design of such applications requires accurate and experimentally validated channel models that characterize the propagation of signaling molecules, not just in individual blood vessels, but in complex vessel networks (VNs), as prevalent in the CVS. However, experimentally validated models for MC in VNs remain scarce. To address this gap, we propose a novel channel model for MC in complex VN topologies, which captures molecular transport via advection, molecular and turbulent diffusion, as well as adsorption and desorption at the vessel walls. We specialize this model for superparamagnetic iron-oxide nanoparticles (SPIONs) as signaling molecules by introducing a new receiver (RX) model for planar coil inductive sensors, enabling end-to-end experimental validation with a dedicated SPION testbed. Validation covers a range of channel topologies, from single-vessel topologies to branched VNs with multiple paths between transmitter (TX) and RX. Additionally, to quantify how the VN topology impacts signal quality, and inspired by multi-path propagation models in conventional wireless communications, we introduce two metrics, namely molecule delay and multi-path spread. We show that these metrics link the VN structure to molecule dispersion induced by the VN and mediately to the resulting signal-to-noise ratio (SNR) at the RX. The proposed VN structure-SNR link is validated experimentally, demonstrating that the proposed framework can support tasks such as optimal sensor placement in the CVS or the identification of suitable testbed topologies for specific SNR requirements. All experimental data are openly available on Zenodo.

- **DF-Mamba: Deformable State Space Modeling for 3D Hand Pose Estimation in Interactions**
  - 发表日期：2025-12-02 | 推荐度：0.808 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02727v1
  - 摘要：Modeling daily hand interactions often struggles with severe occlusions, such as when two hands overlap, which highlights the need for robust feature learning in 3D hand pose estimation (HPE). To handle such occluded hand images, it is vital to effectively learn the relationship between local image features (e.g., for occluded joints) and global context (e.g., cues from inter-joints, inter-hands, or the scene). However, most current 3D HPE methods still rely on ResNet for feature extraction, and such CNN's inductive bias may not be optimal for 3D HPE due to its limited capability to model the global context. To address this limitation, we propose an effective and efficient framework for visual feature extraction in 3D HPE using recent state space modeling (i.e., Mamba), dubbed Deformable Mamba (DF-Mamba). DF-Mamba is designed to capture global context cues beyond standard convolution through Mamba's selective state modeling and the proposed deformable state scanning. Specifically, for local features after convolution, our deformable scanning aggregates these features within an image while selectively preserving useful cues that represent the global context. This approach significantly improves the accuracy of structured 3D HPE, with comparable inference speed to ResNet-50. Our experiments involve extensive evaluations on five divergent datasets including single-hand and two-hand scenarios, hand-only and hand-object interactions, as well as RGB and depth-based estimation. DF-Mamba outperforms the latest image backbones, including VMamba and Spatial-Mamba, on all datasets and achieves state-of-the-art performance.

- **Defense That Attacks: How Robust Models Become Better Attackers**
  - 发表日期：2025-12-02 | 推荐度：0.806 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02830v1
  - 摘要：Deep learning has achieved great success in computer vision, but remains vulnerable to adversarial attacks. Adversarial training is the leading defense designed to improve model robustness. However, its effect on the transferability of attacks is underexplored. In this work, we ask whether adversarial training unintentionally increases the transferability of adversarial examples. To answer this, we trained a diverse zoo of 36 models, including CNNs and ViTs, and conducted comprehensive transferability experiments. Our results reveal a clear paradox: adversarially trained (AT) models produce perturbations that transfer more effectively than those from standard models, which introduce a new ecosystem risk. To enable reproducibility and further study, we release all models, code, and experimental scripts. Furthermore, we argue that robustness evaluations should assess not only the resistance of a model to transferred attacks but also its propensity to produce transferable adversarial examples.

- **Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages**
  - 发表日期：2025-12-02 | 推荐度：0.805 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02841v1
  - 摘要：System prompts provide a lightweight yet powerful mechanism for conditioning large language models (LLMs) at inference time. While prior work has focused on English-only settings, real-world deployments benefit from having a single prompt to operate reliably across languages. This paper presents a comprehensive study of how different system prompts steer models toward accurate and robust cross-lingual behavior. We propose a unified four-dimensional evaluation framework to assess system prompts in multilingual environments. Through large-scale experiments on five languages, three LLMs, and three benchmarks, we uncover that certain prompt components, such as CoT, emotion, and scenario, correlate with robust multilingual behavior. We develop a prompt optimization framework for multilingual settings and show it can automatically discover prompts that improve all metrics by 5-10%. Finally, we analyze over 10 million reasoning units and find that more performant system prompts induce more structured and consistent reasoning patterns, while reducing unnecessary language-switching. Together, we highlight system prompt optimization as a scalable path to accurate and robust multilingual LLM behavior.

- **Mapping code on Coarse Grained Reconfigurable Arrays using a SAT solver**
  - 发表日期：2025-12-02 | 推荐度：0.801 | 来源：arXiv
  - DOI：10.1007/978-3-031-90203-1_40
  - 链接：https://arxiv.org/abs/2512.02884v1
  - 摘要：Emerging low-powered architectures like Coarse-Grain Reconfigurable Arrays (CGRAs) are becoming more common. Often included as co-processors, they are used to accelerate compute-intensive workloads like loops. The speedup obtained is defined by the hardware design of the accelerator and by the quality of the compilation. State of the art (SoA) compilation techniques leverage modulo scheduling to minimize the Iteration Interval (II), exploit the architecture parallelism and, consequentially, reduce the execution time of the accelerated workload. In our work, we focus on improving the compilation process by finding the lowest II for any given topology, through a satisfiability (SAT) formulation of the mapping problem. We introduce a novel schedule, called Kernel Mobility Schedule, to encode all the possible mappings for a given Data Flow Graph (DFG) and for a given II. The schedule is used together with the CGRA architectural information to generate all the constraints necessary to find a valid mapping. Experimental results demonstrate that our method not only reduces compilation time on average but also achieves higher quality mappings compared to existing SoA techniques.

- **On the Performance of Multi-Wavelength Underwater Optical Channels in the Presence of Optical Turbulence**
  - 发表日期：2025-12-02 | 推荐度：0.800 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02913v1
  - 摘要：This paper presents an analysis of the performance of a Gaussian optical beam as it propagates through the turbulent underwater optical channel (UWOC) under the weak turbulence regime, where optical signal experiences significant fading and scattering, all of which can severely degrade communication quality. It is assumed that on-off keying (OOK) modulation with direct detection is utilized to establish a duplex communication link. A multi-wavelength beam approach is implemented to enhance the performance by leveraging the distinct propagation characteristics of different wavelengths. Performance is established in terms of the probability of fade, number of fade per second, mean fade duration, and mean time between fades. The use of multi-wavelength beam is shown to enhance performance by a sizable margin.

- **Towards a fully differentiable digital twin for solar cells**
  - 发表日期：2025-12-02 | 推荐度：0.797 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02904v1
  - 摘要：Maximizing energy yield (EY) - the total electric energy generated by a solar cell within a year at a specific location - is crucial in photovoltaics (PV), especially for emerging technologies. Computational methods provide the necessary insights and guidance for future research. However, existing simulations typically focus on only isolated aspects of solar cells. This lack of consistency highlights the need for a framework unifying all computational levels, from material to cell properties, for accurate prediction and optimization of EY prediction. To address this challenge, a differentiable digital twin, Sol(Di)$^2$T, is introduced to enable comprehensive end-to-end optimization of solar cells. The workflow starts with material properties and morphological processing parameters, followed by optical and electrical simulations. Finally, climatic conditions and geographic location are incorporated to predict the EY. Each step is either intrinsically differentiable or replaced with a machine-learned surrogate model, enabling not only accurate EY prediction but also gradient-based optimization with respect to input parameters. Consequently, Sol(Di)$^2$T extends EY predictions to previously unexplored conditions. Demonstrated for an organic solar cell, the proposed framework marks a significant step towards tailoring solar cells for specific applications while ensuring maximal performance.

- **MICCAI STSR 2025 Challenge: Semi-Supervised Teeth and Pulp Segmentation and CBCT-IOS Registration**
  - 发表日期：2025-12-02 | 推荐度：0.795 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02867v1
  - 摘要：Cone-Beam Computed Tomography (CBCT) and Intraoral Scanning (IOS) are essential for digital dentistry, but annotated data scarcity limits automated solutions for pulp canal segmentation and cross-modal registration. To benchmark semi-supervised learning (SSL) in this domain, we organized the STSR 2025 Challenge at MICCAI 2025, featuring two tasks: (1) semi-supervised segmentation of teeth and pulp canals in CBCT, and (2) semi-supervised rigid registration of CBCT and IOS. We provided 60 labeled and 640 unlabeled IOS samples, plus 30 labeled and 250 unlabeled CBCT scans with varying resolutions and fields of view. The challenge attracted strong community participation, with top teams submitting open-source deep learning-based SSL solutions. For segmentation, leading methods used nnU-Net and Mamba-like State Space Models with pseudo-labeling and consistency regularization, achieving a Dice score of 0.967 and Instance Affinity of 0.738 on the hidden test set. For registration, effective approaches combined PointNetLK with differentiable SVD and geometric augmentation to handle modality gaps; hybrid neural-classical refinement enabled accurate alignment despite limited labels. All data and code are publicly available at https://github.com/ricoleehduu/STS-Challenge-2025 to ensure reproducibility.

- **Perceptual evaluation of Acoustic Level of Detail in Virtual Acoustic Environments**
  - 发表日期：2025-12-02 | 推荐度：0.795 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02891v1
  - 摘要：Virtual acoustic environments enable the creation and simulation of realistic and eco-logically valid daily-life situations vital for hearing research and audiology. Reverberant indoor environments are particularly important. For real-time applications, room acous-tics simulation requires simplifications, however, the necessary acoustic level of detail (ALOD) remains unclear in order to capture all perceptually relevant effects. This study examines the impact of varying ALOD in simulations of three real environments: a living room with a coupled kitchen, a pub, and an underground station. ALOD was varied by generating different numbers of image sources for early reflections, or by excluding geo-metrical room details specific for each environment. Simulations were perceptually eval-uated using headphones in comparison to binaural room impulse responses measured with a dummy head in the corresponding real environments, or by using loudspeakers. The study assessed the perceived overall difference for a pulse stimulus, a played electric bass and a speech token. Additionally, plausibility, speech intelligibility, and externaliza-tion were evaluated. Results indicate that a strong reduction in ALOD is feasible while maintaining similar plausibility, speech intelligibility, and externalization as with dummy head recordings. The number and accuracy of early reflections appear less relevant, pro-vided diffuse late reverberation is appropriately represented.

- **PAC-Bayesian Optimal Control with Stability and Generalization Guarantees**
  - 发表日期：2025-12-02 | 推荐度：0.794 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02858v1
  - 摘要：Stochastic Nonlinear Optimal Control (SNOC) seeks to minimize a cost function that accounts for random disturbances acting on a nonlinear dynamical system. Since the expectation over all disturbances is generally intractable, a common surrogate is the empirical cost, obtained by averaging over a finite dataset of sampled noise realizations. This substitution, however, introduces the challenge of guaranteeing performance under unseen disturbances. The issue is particularly severe when the dataset is limited, as the trained controllers may overfit, leading to substantial gaps between their empirical cost and the deployment cost. In this work, we develop a PAC-Bayesian framework that establishes rigorous generalization bounds for SNOC. Building on these bounds, we propose a principled controller design method that balances empirical performance and prior knowledge. To ensure tractability, we derive computationally efficient relaxations of the bounds and employ approximate inference methods. Our framework further leverages expressive neural controller parameterizations, guaranteeing closed-loop stability. Through simulated examples, we highlight how prior knowledge can be incorporated into control design and how more reliable controllers can be synthesized for cooperative robotics.

- **Identification of Multivariate Measurement Error Models**
  - 发表日期：2025-12-02 | 推荐度：0.788 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02970v1
  - 摘要：This paper develops new identification results for multidimensional continuous measurement-error models where all observed measurements are contaminated by potentially correlated errors and none provides an injective mapping of the latent distribution. Using third order cross moments, the paper constructs a three way tensor whose unique decomposition, guaranteed by Kruskal theorem, identifies the factor loading matrices. Starting with a linear structure, the paper recovers the full distribution of latent factors by constructing suitable measurements and applying scalar or multivariate versions of Kotlarski identity. As a result, the joint distribution of the latent vector and measurement errors is fully identified without requiring injective measurements, showing that multivariate latent structure can be recovered in broader settings than previously believed. Under injectivity, the paper also provides user-friendly testable conditions for identification. Finally, this paper provides general identification results for nonlinear models using a newly-defined generalized Kruskal rank - signal rank - of intergral operators. These results have wide applicability in empirical work involving noisy or indirect measurements, including factor models, survey data with reporting errors, mismeasured regressors in econometrics, and multidimensional latent-trait models in psychology and marketing, potentially enabling more robust estimation and interpretation when clean measurements are unavailable.

- **Probabilistic energy profiler for statically typed JVM-based programming languages**
  - 发表日期：2025-12-02 | 推荐度：0.787 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02738v1
  - 摘要：Energy consumption is a growing concern in several fields, from mobile devices to large data centers. Developers need detailed data on the energy consumption of their software to mitigate consumption issues. Previous approaches have a broader focus, such as on specific functions or programs, rather than source code statements. They primarily focus on estimating the CPU's energy consumption using point estimates, thereby disregarding other hardware effects and limiting their use for statistical reasoning and explainability. We developed a novel methodology to address the limitations of measuring only the CPU's consumption and using point estimates, focusing on predicting the energy usage of statically typed JVM-based programming languages, such as Java and Scala. We measure the energy consumption of Bytecode patterns, the translation from the programming language's source code statement to their Java Bytecode representation. With the energy measurements, we construct a statistical model using Bayesian statistics, which allows us to predict the energy consumption through statistical distributions and analyze individual factors. The model includes three factors we obtain statically from the code: data size, data type, operation, and one factor about the hardware platform the code executes on: device. To validate our methodology, we implemented it for Java and evaluated its energy predictions on unseen programs. We observe that all four factors are influential, notably that two devices of the same model may differ in energy consumption and that the operations and data types cause consumption differences. The experiments also show that the energy prediction of programs closely follows the program's real energy consumption, validating our approach. Our work presents a methodology for constructing an energy model that future work, such as verification tools, can use for their energy estimates.

- **Model-Based Diagnosis with Multiple Observations: A Unified Approach for C Software and Boolean Circuits**
  - 发表日期：2025-12-02 | 推荐度：0.787 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02898v1
  - 摘要：Debugging is one of the most time-consuming and expensive tasks in software development and circuit design. Several formula-based fault localisation (FBFL) methods have been proposed, but they fail to guarantee a set of diagnoses across all failing tests or may produce redundant diagnoses that are not subset-minimal, particularly for programs/circuits with multiple faults.
  This paper introduces CFaults, a novel fault localisation tool for C software and Boolean circuits with multiple faults. CFaults leverages Model-Based Diagnosis (MBD) with multiple observations and aggregates all failing test cases into a unified Maximum Satisfiability (MaxSAT) formula. Consequently, our method guarantees consistency across observations and simplifies the fault localisation procedure. Experimental results on three benchmark sets, two of C programs, TCAS and C-Pack-IPAs, and one of Boolean circuits, ISCAS85, show that CFaults is faster at localising faults in C software than other FBFL approaches such as BugAssist, SNIPER, and HSD. On the ISCAS85 benchmark, CFaults is generally slower than HSD; however, it localises faults in only 6% fewer circuits, demonstrating that it remains competitive in this domain. Furthermore, CFaults produces only subset-minimal diagnoses of faulty statements, whereas the other approaches tend to enumerate redundant diagnoses (e.g., BugAssist and SNIPER).

- **SAT-MapIt: A SAT-based Modulo Scheduling Mapper for Coarse Grain Reconfigurable Architectures**
  - 发表日期：2025-12-02 | 推荐度：0.786 | 来源：arXiv
  - DOI：10.23919/DATE56975.2023.10137123
  - 链接：https://arxiv.org/abs/2512.02875v1
  - 摘要：Coarse-Grain Reconfigurable Arrays (CGRAs) are emerging low-power architectures aimed at accelerating compute-intensive application loops. The acceleration that a CGRA can ultimately provide, however, heavily depends on the quality of the mapping, i.e. on how effectively the loop is compiled onto the given platform. State of the Art compilation techniques achieve mapping through modulo scheduling, a strategy which attempts to minimize the II (Iteration Interval) needed to execute a loop, and they do so usually through well known graph algorithms, such as Max-Clique Enumeration.
  We address the mapping problem through a SAT formulation, instead, and thus explore the solution space more effectively than current SoA tools. To formulate the SAT problem, we introduce an ad-hoc schedule called the \textit{kernel mobility schedule} (KMS), which we use in conjunction with the data-flow graph and the architectural information of the CGRA in order to create a set of boolean statements that describe all constraints to be obeyed by the mapping for a given II. We then let the SAT solver efficiently navigate this complex space. As in other SoA techniques, the process is iterative: if a valid mapping does not exist for the given II, the II is increased and a new KMS and set of constraints is generated and solved.
  Our experimental results show that SAT-MapIt obtains better results compared to SoA alternatives in $47.72\%$ of the benchmarks explored: sometimes finding a lower II, and others even finding a valid mapping when none could previously be found.

- **Phase-Adaptive LLM Framework with Multi-Stage Validation for Construction Robot Task Allocation: A Systematic Benchmark Against Traditional Optimization Algorithms**
  - 发表日期：2025-12-02 | 推荐度：0.784 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02810v1
  - 摘要：Multi-robot task allocation in construction automation has traditionally relied on optimization methods such as Dynamic Programming and Reinforcement Learning. This research introduces the LangGraph-based Task Allocation Agent (LTAA), an LLM-driven framework that integrates phase-adaptive allocation strategies, multi-stage validation with hierarchical retries, and dynamic prompting for efficient robot coordination. Although recent LLM approaches show potential for construction robotics, they largely lack rigorous validation and benchmarking against established algorithms. This paper presents the first systematic comparison of LLM-based task allocation with traditional methods in construction scenarios.The study validates LLM feasibility through SMART-LLM replication and addresses implementation challenges using a Self-Corrective Agent Architecture. LTAA leverages natural-language reasoning combined with structured validation mechanisms, achieving major computational gains reducing token usage by 94.6% and allocation time by 86% through dynamic prompting. The framework adjusts its strategy across phases: emphasizing execution feasibility early and workload balance in later allocations.The authors evaluate LTAA against Dynamic Programming, Q-learning, and Deep Q-Network (DQN) baselines using construction operations from the TEACh human-robot collaboration dataset. In the Heavy Excels setting, where robots have strong task specializations, LTAA achieves 77% task completion with superior workload balance, outperforming all traditional methods. These findings show that LLM-based reasoning with structured validation can match established optimization algorithms while offering additional advantages such as interpretability, adaptability, and the ability to update task logic without retraining.

- **Belobog: Move Language Fuzzing Framework For Real-World Smart Contracts**
  - 发表日期：2025-12-02 | 推荐度：0.782 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02918v1
  - 摘要：Move is a research-oriented programming language design for secure and verifiable smart contract development and has been widely used in managing billions of digital assets in blockchains, such as Sui and Aptos. Move features a strong static type system and explicit resource semantics to enforce safety properties such as the prevention of data races, invalid asset transfers, and entry vulnerabilities. However, smart contracts written in Move may still contain certain vulnerabilities that are beyond the reach of its type system. It is thus essential to validate Move smart contracts. Unfortunately, due to its strong type system, existing smart contract fuzzers are ineffective in producing syntactically or semantically valid transactions to test Move smart contracts. This paper introduces the first fuzzing framework, Belobog, for Move smart contracts. Belobog is type-aware and ensures that all generated and mutated transactions are well-typed. More specifically, for a target Move smart contract, Belobog first constructs a type graph based on Move's type system, and then generates or mutates a transaction based on the graph trace derived from the type graph. In order to overcome the complex checks in Move smart contracts, we further design and implement a concolic executor in Belobog. We evaluated Belobog on 109 real-world Move smart contract projects. The experimental results show that Belobog is able to detect 100\% critical and 79\% major vulnerabilities manually audited by human experts. We further selected two recent notorious incidents in Move smart contracts, i.e., Cetus and Nemo. Belobog successfully reproduced full exploits for both of them, without any prior knowledge.

- **Devil's Games and $\text{Q}\mathbb{R}$: Continuous Games complete for the First-Order Theory of the Reals**
  - 发表日期：2025-12-02 | 推荐度：0.781 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02779v1
  - 摘要：We introduce the complexity class Quantified Reals ($\text{Q}\mathbb{R}$). Let FOTR be the set of true sentences in the first-order theory of the reals. A language $L$ is in $\text{Q}\mathbb{R}$, if there is a polynomial time reduction from $L$ to FOTR. This seems the first time this complexity class is studied. We show that $\text{Q}\mathbb{R}$ can also be defined using real Turing machines. It is known that deciding FOTR requires at least exponential time unconditionally [Berman, 1980].
  We focus on devil's games with two defining properties: (1) Players (human and devil) alternate turns and (2) each turn has a continuum of options.
  First, we show that FOTRINV is $\text{Q}\mathbb{R}$-complete. FOTRINV has only inversion and addition constraints and all variables are in a compact interval. FOTRINV is a stepping stone for further reductions.
  Second, we show that the Packing Game is $\text{Q}\mathbb{R}$-complete. In the Packing Game we are given a container and two sets of pieces. One set of pieces for the human and one set for the devil. The human and the devil alternate by placing a piece into the container. Both rotations and translations are allowed. The first player that cannot place a piece loses.
  Third, we show that the Planar Extension Game is $\text{Q}\mathbb{R}$-complete. We are given a partially drawn plane graph and the human and the devil alternate by placing vertices and the corresponding edges in a straight-line manner. The vertices and edges to be placed are prescribed before hand. The first player that cannot place a vertex loses.
  Finally, we show that the Order Type Game is $\text{Q}\mathbb{R}$-complete. We are given an order-type together with a linear order. The human and the devil alternate in placing a point in the Euclidean plane following the linear order. The first player that cannot place a point correctly loses.

- **Implicit score-driven filters for time-varying parameter models**
  - 发表日期：2025-12-02 | 推荐度：0.780 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02744v1
  - 摘要：We propose an observation-driven modeling framework that permits time variation in the model parameters using an implicit score-driven (ISD) update. The ISD update maximizes the logarithmic observation density with respect to the parameter vector, while penalizing the weighted L2 norm relative to a one-step-ahead predicted parameter. This yields an implicit stochastic-gradient update. We show that the popular class of explicit score-driven (ESD) models arises if the observation log density is linearly approximated around the prediction. By preserving the full density, the ISD update globalizes favorable local properties of the ESD update. Namely, for log-concave observation densities, whether correctly specified or not, the ISD filter is stable for all learning rates, while its updates are contractive in mean squared error toward the (pseudo-)true parameter at every time step. We demonstrate the usefulness of ISD filters in simulations and empirical illustrations in finance and macroeconomics.

- **Stability of quantum chaos against weak non-unitarity**
  - 发表日期：2025-12-02 | 推荐度：0.774 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02934v1
  - 摘要：We study the quantum dynamics generated by the repeated action of a non-unitary evolution operator on a system of qubits. Breaking unitarity can lead to the purification of mixed initial states, which corresponds to the loss of sensitivity to initial conditions, and hence the absence of a key signature of dynamical chaos. However, the scrambling of quantum information can delay purification to times that are exponential in system size. Here we study purification in systems whose evolution operators are fixed in time, where all aspects of the dynamics are in principle encoded in spectral properties of the evolution operator for a single time step. The operators that we study consist of global Haar random unitary operators and non-unitary single-qubit operations. We show that exponentially slow purification arises from a distribution of eigenvalues in the complex plane that forms a ring with sharp edges at large radii, with the eigenvalue density exponentially large near these edges. We argue that the sharp edges of the eigenvalue distribution arise from level attraction along the radial direction in the complex plane. By calculating the spectral form factor we also show that there is level repulsion around the azimuthal direction, even close to the outer edge of the ring of eigenvalues. Our results connect this spectral signature of quantum chaos to the sensitivity of the system to its initial conditions.

- **Syntomic formalism with coefficients**
  - 发表日期：2025-12-02 | 推荐度：0.774 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02905v1
  - 摘要：This paper provides the technical tools needed in ongoing work of the authors to compute p-adic étale Abel-Jacobi maps in order to obtain explicit reciprocity laws for GSp4. In particular, we define and study syntomic polynomial cohomology for filtered Frobenius log-isocrystals over proper and semistable schemes over the ring of integers of a local field, with smooth generic fiber, endowed with horizontal divisors. We introduce syntomic polynomial cohomology with support, we define Kunneth morphisms, trace maps and cup products, Gysin maps with respect to divisors and we study some of their properties. We establish the relation with Hyodo-Kato cohomology of the special fiber and de Rham cohomology of the generic fiber. We also introduce overconvergent variants with and without support by restricting to open smooth formal subschemes. Most of all, in case that the filtered log-isocrystal is associated to a p-adic local system on the generic fiber, we establish comparison morphisms between étale and syntomic cohomology and compatibilities with Hochschild-Serre morphisms and between Gysin morphisms.
