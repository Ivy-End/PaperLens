## 每日论文推荐 — 2025-12-02

- **LumiX: Structured and Coherent Text-to-Intrinsic Generation**
  - 发表日期：2025-12-02 | 推荐度：0.883 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02781v1
  - 摘要：We present LumiX, a structured diffusion framework for coherent text-to-intrinsic generation. Conditioned on text prompts, LumiX jointly generates a comprehensive set of intrinsic maps (e.g., albedo, irradiance, normal, depth, and final color), providing a structured and physically consistent description of an underlying scene. This is enabled by two key contributions: 1) Query-Broadcast Attention, a mechanism that ensures structural consistency by sharing queries across all maps in each self-attention block. 2) Tensor LoRA, a tensor-based adaptation that parameter-efficiently models cross-map relations for efficient joint training. Together, these designs enable stable joint diffusion training and unified generation of multiple intrinsic properties. Experiments show that LumiX produces coherent and physically meaningful results, achieving 23% higher alignment and a better preference score (0.19 vs. -0.41) compared to the state of the art, and it can also perform image-conditioned intrinsic decomposition within the same framework.

- **Diffusion-Prior Split Gibbs Sampling for Synthetic Aperture Radar Imaging under Incomplete Measurements**
  - 发表日期：2025-12-02 | 推荐度：0.880 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02768v1
  - 摘要：Synthetic aperture radar (SAR) imaging plays a critical role in all-weather, day-and-night remote sensing, yet reconstruction is often challenged by noise, undersampling, and complex scattering scenarios. Conventional methods, including matched filtering and sparsity-based compressed sensing, are limited in capturing intricate scene structures and frequently suffer from artifacts, elevated sidelobes, and loss of fine details. Recent diffusion models have demonstrated superior capability in representing high-order priors; however, existing diffusion-based SAR methods still yield degraded reconstructions due to oversimplified likelihood approximations in guided sampling. In this work, we propose a diffusion-driven split Gibbs sampling framework for SAR reconstruction, rigorously integrating measurement fidelity with learned diffusion priors. By alternately performing likelihood- and prior-driven updates via proximal sampling, this method ensures progressive convergence toward the true posterior while fully leveraging the expressive power of diffusion priors. Extensive experiments on simulated and Sentinel-1A datasets demonstrate substantial performance improvements: over 7 dB average PSNR gain in simulations, along with significant sidelobe suppression (MPLSR +2.96 dB, MISLR +11.5 dB) with respect to the best baseline result. On real-world Sentinel-1A data, the method achieves an average PSNR gain of 1.6 dB while effectively reducing artifacts and preserving scene details, including ridges, edges, and fine textures. These results underscore the potential of the adapted framework as a robust and generalizable solution for high-fidelity SAR imaging across diverse sensing scenarios.

- **Channel Knowledge Map Construction via Physics-Inspired Diffusion Model Without Prior Observations**
  - 发表日期：2025-12-02 | 推荐度：0.879 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02757v1
  - 摘要：The ability to construct Channel Knowledge Map (CKM) with high precision is essential for environment awareness in 6G wireless systems. However, most existing CKM construction methods formulate the task as an image super-resolution or generation problem, thereby employing models originally developed for computer vision. As a result, the generated CKMs often fail to capture the underlying physical characteristics of wireless propagation. In this paper, we focus on the construction of CKM for large-scale fading scenarios and design three physics-based constraint terms to characterize the spatial distribution patterns of large-scale fading. By integrating these physical constraints with a state-of-the-art diffusion model that possesses superior generative capability, a physics-inspired diffusion model for CKM construction is proposed. Following this motivation, we derive the loss function of the diffusion model augmented with physics-based constraint terms and further design the training and generation framework for the proposed physics-inspired CKM generation diffusion model. Extensive experiments show that our approach outperforms all existing methods in terms of construction accuracy. Moreover, the proposed model provides a unified and effective framework with strong potential for generating diverse, accurate, and physically consistent CKM.

- **Steering Vision-Language-Action Models as Anti-Exploration: A Test-Time Scaling Approach**
  - 发表日期：2025-12-02 | 推荐度：0.879 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02834v1
  - 摘要：Vision-Language-Action (VLA) models, trained via flow-matching or diffusion objectives, excel at learning complex behaviors from large-scale, multi-modal datasets (e.g., human teleoperation, scripted policies). However, since VLAs incorporate diverse data modes in the pre-training stage, and the finetuning dataset often contains demonstration data collected in a kinematically suboptimal or undesirable way, it exists redundant action modes that are irrelevant to the success action modes of the downstream task. Specifically, we observe a critical inference-time fragility among various sampled noises after supervised finetuning of pre-trained VLAs. In this paper, we attribute this instability to the distribution shift between the VLA policy and the policy induced by stable success modes of the downstream task dataset. Thus, we propose \textbf{TACO}, a test-time-scaling (TTS) framework that applies a lightweight pseudo-count estimator as a high-fidelity verifier of action chunks. The VLA models integrated with TACO can execute the actions with maximum pseudo-count from all sampled action chunks, thereby preventing distribution shifts while preserving the generalization ability of VLAs since the constraint is applied only during inference. Our method resembles the classical anti-exploration principle in offline reinforcement learning (RL), and being gradient-free, it incurs significant computational benefits compared to RL update, especially for flow or diffusion-based VLAs which are difficult to perform RL update due to denoising process. Extensive experiments across four simulation benchmarks (RoboTwin2.0, Robotwin, LIBERO, SimplerEnv) and a dual-arm platform demonstrate that our method significantly improves the inference stability and success rates in downstream-task adaptations.

- **MagicQuillV2: Precise and Interactive Image Editing with Layered Visual Cues**
  - 发表日期：2025-12-02 | 推荐度：0.873 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.03046v1
  - 摘要：We propose MagicQuill V2, a novel system that introduces a \textbf{layered composition} paradigm to generative image editing, bridging the gap between the semantic power of diffusion models and the granular control of traditional graphics software. While diffusion transformers excel at holistic generation, their use of singular, monolithic prompts fails to disentangle distinct user intentions for content, position, and appearance. To overcome this, our method deconstructs creative intent into a stack of controllable visual cues: a content layer for what to create, a spatial layer for where to place it, a structural layer for how it is shaped, and a color layer for its palette. Our technical contributions include a specialized data generation pipeline for context-aware content integration, a unified control module to process all visual cues, and a fine-tuned spatial branch for precise local editing, including object removal. Extensive experiments validate that this layered approach effectively resolves the user intention gap, granting creators direct, intuitive control over the generative process.

- **Identification of Multivariate Measurement Error Models**
  - 发表日期：2025-12-02 | 推荐度：0.866 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02970v1
  - 摘要：This paper develops new identification results for multidimensional continuous measurement-error models where all observed measurements are contaminated by potentially correlated errors and none provides an injective mapping of the latent distribution. Using third order cross moments, the paper constructs a three way tensor whose unique decomposition, guaranteed by Kruskal theorem, identifies the factor loading matrices. Starting with a linear structure, the paper recovers the full distribution of latent factors by constructing suitable measurements and applying scalar or multivariate versions of Kotlarski identity. As a result, the joint distribution of the latent vector and measurement errors is fully identified without requiring injective measurements, showing that multivariate latent structure can be recovered in broader settings than previously believed. Under injectivity, the paper also provides user-friendly testable conditions for identification. Finally, this paper provides general identification results for nonlinear models using a newly-defined generalized Kruskal rank - signal rank - of intergral operators. These results have wide applicability in empirical work involving noisy or indirect measurements, including factor models, survey data with reporting errors, mismeasured regressors in econometrics, and multidimensional latent-trait models in psychology and marketing, potentially enabling more robust estimation and interpretation when clean measurements are unavailable.

- **DF-Mamba: Deformable State Space Modeling for 3D Hand Pose Estimation in Interactions**
  - 发表日期：2025-12-02 | 推荐度：0.865 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02727v1
  - 摘要：Modeling daily hand interactions often struggles with severe occlusions, such as when two hands overlap, which highlights the need for robust feature learning in 3D hand pose estimation (HPE). To handle such occluded hand images, it is vital to effectively learn the relationship between local image features (e.g., for occluded joints) and global context (e.g., cues from inter-joints, inter-hands, or the scene). However, most current 3D HPE methods still rely on ResNet for feature extraction, and such CNN's inductive bias may not be optimal for 3D HPE due to its limited capability to model the global context. To address this limitation, we propose an effective and efficient framework for visual feature extraction in 3D HPE using recent state space modeling (i.e., Mamba), dubbed Deformable Mamba (DF-Mamba). DF-Mamba is designed to capture global context cues beyond standard convolution through Mamba's selective state modeling and the proposed deformable state scanning. Specifically, for local features after convolution, our deformable scanning aggregates these features within an image while selectively preserving useful cues that represent the global context. This approach significantly improves the accuracy of structured 3D HPE, with comparable inference speed to ResNet-50. Our experiments involve extensive evaluations on five divergent datasets including single-hand and two-hand scenarios, hand-only and hand-object interactions, as well as RGB and depth-based estimation. DF-Mamba outperforms the latest image backbones, including VMamba and Spatial-Mamba, on all datasets and achieves state-of-the-art performance.

- **ReVSeg: Incentivizing the Reasoning Chain for Video Segmentation with Reinforcement Learning**
  - 发表日期：2025-12-02 | 推荐度：0.863 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02835v1
  - 摘要：Reasoning-centric video object segmentation is an inherently complex task: the query often refers to dynamics, causality, and temporal interactions, rather than static appearances. Yet existing solutions generally collapse these factors into simplified reasoning with latent embeddings, rendering the reasoning chain opaque and essentially intractable. We therefore adopt an explicit decomposition perspective and introduce ReVSeg, which executes reasoning as sequential decisions in the native interface of pretrained vision language models (VLMs). Rather than folding all reasoning into a single-step prediction, ReVSeg executes three explicit operations -- semantics interpretation, temporal evidence selection, and spatial grounding -- aligning pretrained capabilities. We further employ reinforcement learning to optimize the multi-step reasoning chain, enabling the model to self-refine its decision quality from outcome-driven signals. Experimental results demonstrate that ReVSeg attains state-of-the-art performances on standard video object segmentation benchmarks and yields interpretable reasoning trajectories. Project page is available at https://clementine24.github.io/ReVSeg/ .

- **Towards Unification of Hallucination Detection and Fact Verification for Large Language Models**
  - 发表日期：2025-12-02 | 推荐度：0.862 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02772v1
  - 摘要：Large Language Models (LLMs) frequently exhibit hallucinations, generating content that appears fluent and coherent but is factually incorrect. Such errors undermine trust and hinder their adoption in real-world applications. To address this challenge, two distinct research paradigms have emerged: model-centric Hallucination Detection (HD) and text-centric Fact Verification (FV). Despite sharing the same goal, these paradigms have evolved in isolation, using distinct assumptions, datasets, and evaluation protocols. This separation has created a research schism that hinders their collective progress. In this work, we take a decisive step toward bridging this divide. We introduce UniFact, a unified evaluation framework that enables direct, instance-level comparison between FV and HD by dynamically generating model outputs and corresponding factuality labels. Through large-scale experiments across multiple LLM families and detection methods, we reveal three key findings: (1) No paradigm is universally superior; (2) HD and FV capture complementary facets of factual errors; and (3) hybrid approaches that integrate both methods consistently achieve state-of-the-art performance. Beyond benchmarking, we provide the first in-depth analysis of why FV and HD diverged, as well as empirical evidence supporting the need for their unification. The comprehensive experimental results call for a new, integrated research agenda toward unifying Hallucination Detection and Fact Verification in LLMs.
  We have open-sourced all the code, data, and baseline implementation at: https://github.com/oneal2000/UniFact/

- **promptolution: A Unified, Modular Framework for Prompt Optimization**
  - 发表日期：2025-12-02 | 推荐度：0.861 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02840v1
  - 摘要：Prompt optimization has become crucial for enhancing the performance of large language models (LLMs) across a broad range of tasks. Although many research papers show its effectiveness, practical adoption is hindered as existing implementations are often tied to unmaintained and isolated research codebases. To address this, we introduce promptolution, a unified and modular open-source framework that provides all components required for prompt optimization within a single extensible system for both practitioners and researchers. It integrates multiple contemporary discrete prompt optimizers while remaining agnostic to the underlying LLM implementation.

- **OneThinker: All-in-one Reasoning Model for Image and Video**
  - 发表日期：2025-12-02 | 推荐度：0.861 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.03043v1
  - 摘要：Reinforcement learning (RL) has recently achieved remarkable success in eliciting visual reasoning within Multimodal Large Language Models (MLLMs). However, existing approaches typically train separate models for different tasks and treat image and video reasoning as disjoint domains. This results in limited scalability toward a multimodal reasoning generalist, which restricts practical versatility and hinders potential knowledge sharing across tasks and modalities. To this end, we propose OneThinker, an all-in-one reasoning model that unifies image and video understanding across diverse fundamental visual tasks, including question answering, captioning, spatial and temporal grounding, tracking, and segmentation. To achieve this, we construct the OneThinker-600k training corpus covering all these tasks and employ commercial models for CoT annotation, resulting in OneThinker-SFT-340k for SFT cold start. Furthermore, we propose EMA-GRPO to handle reward heterogeneity in multi-task RL by tracking task-wise moving averages of reward standard deviations for balanced optimization. Extensive experiments on diverse visual benchmarks show that OneThinker delivers strong performance on 31 benchmarks, across 10 fundamental visual understanding tasks. Moreover, it exhibits effective knowledge transfer between certain tasks and preliminary zero-shot generalization ability, marking a step toward a unified multimodal reasoning generalist. All code, model, and data are released.

- **Implicit score-driven filters for time-varying parameter models**
  - 发表日期：2025-12-02 | 推荐度：0.861 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02744v1
  - 摘要：We propose an observation-driven modeling framework that permits time variation in the model parameters using an implicit score-driven (ISD) update. The ISD update maximizes the logarithmic observation density with respect to the parameter vector, while penalizing the weighted L2 norm relative to a one-step-ahead predicted parameter. This yields an implicit stochastic-gradient update. We show that the popular class of explicit score-driven (ESD) models arises if the observation log density is linearly approximated around the prediction. By preserving the full density, the ISD update globalizes favorable local properties of the ESD update. Namely, for log-concave observation densities, whether correctly specified or not, the ISD filter is stable for all learning rates, while its updates are contractive in mean squared error toward the (pseudo-)true parameter at every time step. We demonstrate the usefulness of ISD filters in simulations and empirical illustrations in finance and macroeconomics.

- **Mapping code on Coarse Grained Reconfigurable Arrays using a SAT solver**
  - 发表日期：2025-12-02 | 推荐度：0.860 | 来源：arXiv
  - DOI：10.1007/978-3-031-90203-1_40
  - 链接：https://arxiv.org/abs/2512.02884v1
  - 摘要：Emerging low-powered architectures like Coarse-Grain Reconfigurable Arrays (CGRAs) are becoming more common. Often included as co-processors, they are used to accelerate compute-intensive workloads like loops. The speedup obtained is defined by the hardware design of the accelerator and by the quality of the compilation. State of the art (SoA) compilation techniques leverage modulo scheduling to minimize the Iteration Interval (II), exploit the architecture parallelism and, consequentially, reduce the execution time of the accelerated workload. In our work, we focus on improving the compilation process by finding the lowest II for any given topology, through a satisfiability (SAT) formulation of the mapping problem. We introduce a novel schedule, called Kernel Mobility Schedule, to encode all the possible mappings for a given Data Flow Graph (DFG) and for a given II. The schedule is used together with the CGRA architectural information to generate all the constraints necessary to find a valid mapping. Experimental results demonstrate that our method not only reduces compilation time on average but also achieves higher quality mappings compared to existing SoA techniques.

- **Maintaining SUV Accuracy in Low-Count PET with PETfectior: A Deep Learning Denoising Solution**
  - 发表日期：2025-12-02 | 推荐度：0.858 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02917v1
  - 摘要：Background: Diagnostic PET image quality depends on the administered activity and acquisition time. However, minimizing these variables is desirable to reduce patient radiation exposure and radiopharmaceutical costs. PETfectior is an artificial intelligence-based software that processes PET scans and increases signal-to-noise ratio, obtaining high-quality images from low-count-rate images. We perform an initial clinical validation of PETfectior on images acquired with half of the counting statistics required to meet the most recent EANM quantitative standards for 18F-FDG PET, evaluating lesions detectability, quantitative performance and image quality.
  Materials and methods: 258 patients referred for 18F-FDG PET/CT were prospectively included. The standard-of-care scans (100% scans) were acquired and reconstructed according to EARL standards 2. Half-counting-statistics versions were generated from list-mode data and processed with PETfecftior (50%+PETfectior scans). All oncologic lesions were segmented on both PET/CT versions, manually or automatically, and lesions detectability was evaluated. The SUVmax of the lesions was measured and the quantitative concordance of 50%+PETfectior and 100% images was evaluated. Subjective image quality was visually assessed by two experienced physicians.
  Results: 1649 lesions were detected in a total of 198 studies. The 50%+PETfectior images showed high sensitivity for lesion detection (99.9%) and only 1 false positive was detected. The SUVmax measured in 100% and 50%+PETfectior images agreed within 12.5% (95% limits of agreement), with a bias of -1.01%. Image quality of the 50%+PETfectior images was rated equal to or better than the standard-of-care images.
  Conclusion: PETfectior can safely be used in clinical practice at half counting statistics, with high sensitivity and specificity, low quantitative bias and high subjective image quality.

- **U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences**
  - 发表日期：2025-12-02 | 推荐度：0.857 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02982v1
  - 摘要：Modeling dynamic 3D environments from LiDAR sequences is central to building reliable 4D worlds for autonomous driving and embodied AI. Existing generative frameworks, however, often treat all spatial regions uniformly, overlooking the varying uncertainty across real-world scenes. This uniform generation leads to artifacts in complex or ambiguous regions, limiting realism and temporal stability. In this work, we present U4D, an uncertainty-aware framework for 4D LiDAR world modeling. Our approach first estimates spatial uncertainty maps from a pretrained segmentation model to localize semantically challenging regions. It then performs generation in a "hard-to-easy" manner through two sequential stages: (1) uncertainty-region modeling, which reconstructs high-entropy regions with fine geometric fidelity, and (2) uncertainty-conditioned completion, which synthesizes the remaining areas under learned structural priors. To further ensure temporal coherence, U4D incorporates a mixture of spatio-temporal (MoST) block that adaptively fuses spatial and temporal representations during diffusion. Extensive experiments show that U4D produces geometrically faithful and temporally consistent LiDAR sequences, advancing the reliability of 4D world modeling for autonomous perception and simulation.

- **Rethinking Generalized BCIs: Benchmarking 340,000+ Unique Algorithmic Configurations for EEG Mental Command Decoding**
  - 发表日期：2025-12-02 | 推荐度：0.856 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02978v1
  - 摘要：Robust decoding and classification of brain patterns measured with electroencephalography (EEG) remains a major challenge for real-world (i.e. outside scientific lab and medical facilities) brain-computer interface (BCI) applications due to well documented inter- and intra-participant variability. Here, we present a large-scale benchmark evaluating over 340,000+ unique combinations of spatial and nonlinear EEG classification. Our methodological pipeline consists in combinations of Common Spatial Patterns (CSP), Riemannian geometry, functional connectivity, and fractal- or entropy-based features across three open-access EEG datasets. Unlike prior studies, our analysis operates at the per-participant level and across multiple frequency bands (8-15 Hz and 8-30 Hz), enabling direct assessment of both group-level performance and individual variability. Covariance tangent space projection (cov-tgsp) and CSP consistently achieved the highest average classification accuracies. However, their effectiveness was strongly dataset-dependent, and marked participant-level differences persisted, particularly in the most heterogeneous of the datasets. Importantly, nonlinear methods outperformed spatial approaches for specific individuals, underscoring the need for personalized pipeline selection. Our findings highlight that no universal 'one-size-fits-all' method can optimally decode EEG motor imagery patterns across all users or datasets. Future work will require adaptive, multimodal, and possibly novel approaches to fully address neurophysiological variability in practical BCI applications where the system can automatically adapt to what makes each user unique.

- **Defense That Attacks: How Robust Models Become Better Attackers**
  - 发表日期：2025-12-02 | 推荐度：0.856 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02830v1
  - 摘要：Deep learning has achieved great success in computer vision, but remains vulnerable to adversarial attacks. Adversarial training is the leading defense designed to improve model robustness. However, its effect on the transferability of attacks is underexplored. In this work, we ask whether adversarial training unintentionally increases the transferability of adversarial examples. To answer this, we trained a diverse zoo of 36 models, including CNNs and ViTs, and conducted comprehensive transferability experiments. Our results reveal a clear paradox: adversarially trained (AT) models produce perturbations that transfer more effectively than those from standard models, which introduce a new ecosystem risk. To enable reproducibility and further study, we release all models, code, and experimental scripts. Furthermore, we argue that robustness evaluations should assess not only the resistance of a model to transferred attacks but also its propensity to produce transferable adversarial examples.

- **Probabilistic energy profiler for statically typed JVM-based programming languages**
  - 发表日期：2025-12-02 | 推荐度：0.855 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02738v1
  - 摘要：Energy consumption is a growing concern in several fields, from mobile devices to large data centers. Developers need detailed data on the energy consumption of their software to mitigate consumption issues. Previous approaches have a broader focus, such as on specific functions or programs, rather than source code statements. They primarily focus on estimating the CPU's energy consumption using point estimates, thereby disregarding other hardware effects and limiting their use for statistical reasoning and explainability. We developed a novel methodology to address the limitations of measuring only the CPU's consumption and using point estimates, focusing on predicting the energy usage of statically typed JVM-based programming languages, such as Java and Scala. We measure the energy consumption of Bytecode patterns, the translation from the programming language's source code statement to their Java Bytecode representation. With the energy measurements, we construct a statistical model using Bayesian statistics, which allows us to predict the energy consumption through statistical distributions and analyze individual factors. The model includes three factors we obtain statically from the code: data size, data type, operation, and one factor about the hardware platform the code executes on: device. To validate our methodology, we implemented it for Java and evaluated its energy predictions on unseen programs. We observe that all four factors are influential, notably that two devices of the same model may differ in energy consumption and that the operations and data types cause consumption differences. The experiments also show that the energy prediction of programs closely follows the program's real energy consumption, validating our approach. Our work presents a methodology for constructing an energy model that future work, such as verification tools, can use for their energy estimates.

- **PAC-Bayesian Optimal Control with Stability and Generalization Guarantees**
  - 发表日期：2025-12-02 | 推荐度：0.855 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02858v1
  - 摘要：Stochastic Nonlinear Optimal Control (SNOC) seeks to minimize a cost function that accounts for random disturbances acting on a nonlinear dynamical system. Since the expectation over all disturbances is generally intractable, a common surrogate is the empirical cost, obtained by averaging over a finite dataset of sampled noise realizations. This substitution, however, introduces the challenge of guaranteeing performance under unseen disturbances. The issue is particularly severe when the dataset is limited, as the trained controllers may overfit, leading to substantial gaps between their empirical cost and the deployment cost. In this work, we develop a PAC-Bayesian framework that establishes rigorous generalization bounds for SNOC. Building on these bounds, we propose a principled controller design method that balances empirical performance and prior knowledge. To ensure tractability, we derive computationally efficient relaxations of the bounds and employ approximate inference methods. Our framework further leverages expressive neural controller parameterizations, guaranteeing closed-loop stability. Through simulated examples, we highlight how prior knowledge can be incorporated into control design and how more reliable controllers can be synthesized for cooperative robotics.

- **The Gamma-disordered Aztec diamond**
  - 发表日期：2025-12-02 | 推荐度：0.853 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.03033v1
  - 摘要：We introduce a multi-parameter family of random edge weights on the Aztec diamond graph, given by certain Gamma variables, and prove several results about the corresponding random dimer measures.
  Firstly, we show there is no phase transition at the level of the free energy. This provides rigorous backing for the physics predictions of Zeng-Leath-Hwa and later works that dimer models with random weights are in the glassy `super-rough' phase at all temperatures with no phase transition.
  Secondly, we show that the random dimer covers themselves enjoy exact distributional equalities of certain marginals with path locations in new `hybrid' integrable polymers. These reduce to the stationary log-Gamma, strict-weak, and Beta polymer in random environment in certain cases, allowing transfer of known results from integrable polymers to dimers with random weights. As an example application, we prove that the turning points at the boundaries of the Aztec diamond exhibit fluctuations of order $n^{2/3}$, in contrast to the $n^{1/2}$ fluctuations for deterministic weights.
  Underlying all these is a key integrability property of the weights: they are the unique family for which independence is preserved under the shuffling algorithm.

- **Phase-Adaptive LLM Framework with Multi-Stage Validation for Construction Robot Task Allocation: A Systematic Benchmark Against Traditional Optimization Algorithms**
  - 发表日期：2025-12-02 | 推荐度：0.852 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02810v1
  - 摘要：Multi-robot task allocation in construction automation has traditionally relied on optimization methods such as Dynamic Programming and Reinforcement Learning. This research introduces the LangGraph-based Task Allocation Agent (LTAA), an LLM-driven framework that integrates phase-adaptive allocation strategies, multi-stage validation with hierarchical retries, and dynamic prompting for efficient robot coordination. Although recent LLM approaches show potential for construction robotics, they largely lack rigorous validation and benchmarking against established algorithms. This paper presents the first systematic comparison of LLM-based task allocation with traditional methods in construction scenarios.The study validates LLM feasibility through SMART-LLM replication and addresses implementation challenges using a Self-Corrective Agent Architecture. LTAA leverages natural-language reasoning combined with structured validation mechanisms, achieving major computational gains reducing token usage by 94.6% and allocation time by 86% through dynamic prompting. The framework adjusts its strategy across phases: emphasizing execution feasibility early and workload balance in later allocations.The authors evaluate LTAA against Dynamic Programming, Q-learning, and Deep Q-Network (DQN) baselines using construction operations from the TEACh human-robot collaboration dataset. In the Heavy Excels setting, where robots have strong task specializations, LTAA achieves 77% task completion with superior workload balance, outperforming all traditional methods. These findings show that LLM-based reasoning with structured validation can match established optimization algorithms while offering additional advantages such as interpretability, adaptability, and the ability to update task logic without retraining.

- **Perceptual evaluation of Acoustic Level of Detail in Virtual Acoustic Environments**
  - 发表日期：2025-12-02 | 推荐度：0.852 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02891v1
  - 摘要：Virtual acoustic environments enable the creation and simulation of realistic and eco-logically valid daily-life situations vital for hearing research and audiology. Reverberant indoor environments are particularly important. For real-time applications, room acous-tics simulation requires simplifications, however, the necessary acoustic level of detail (ALOD) remains unclear in order to capture all perceptually relevant effects. This study examines the impact of varying ALOD in simulations of three real environments: a living room with a coupled kitchen, a pub, and an underground station. ALOD was varied by generating different numbers of image sources for early reflections, or by excluding geo-metrical room details specific for each environment. Simulations were perceptually eval-uated using headphones in comparison to binaural room impulse responses measured with a dummy head in the corresponding real environments, or by using loudspeakers. The study assessed the perceived overall difference for a pulse stimulus, a played electric bass and a speech token. Additionally, plausibility, speech intelligibility, and externaliza-tion were evaluated. Results indicate that a strong reduction in ALOD is feasible while maintaining similar plausibility, speech intelligibility, and externalization as with dummy head recordings. The number and accuracy of early reflections appear less relevant, pro-vided diffuse late reverberation is appropriately represented.

- **Asymptotics for additive functionals of particle systems via Stein's method**
  - 发表日期：2025-12-02 | 推荐度：0.852 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02922v1
  - 摘要：We consider additive functionals of systems of random measures whose initial configuration is given by a Poisson point process, and whose individual components evolve according to arbitrary Markovian or non-Markovian measure valued dynamics, with no structural assumptions beyond basic moment bounds. In this setting and under adequate conditions, we establish a general third moment theorem for the normalized functionals. Building on this result, we obtain the first quantitative bounds in the Wasserstein distance for a variety of moving-measure models initialized by Poisson-driven clouds of points, turning qualitative central limit theorems into explicit rates of convergence. The scope of the approach is then demonstrated through several examples, including systems driven by fractional Brownian motion, $α$-stable processes, uniformly elliptic diffusions, and spectral empirical measures arising from Dyson Brownian motion, all under broad assumptions on the control measure of the initial Poisson configuration. The analysis relies on a combination of Stein's method with Mecke's formula, in the spirit of the Poisson Malliavin-Stein methodology.

- **Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages**
  - 发表日期：2025-12-02 | 推荐度：0.850 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02841v1
  - 摘要：System prompts provide a lightweight yet powerful mechanism for conditioning large language models (LLMs) at inference time. While prior work has focused on English-only settings, real-world deployments benefit from having a single prompt to operate reliably across languages. This paper presents a comprehensive study of how different system prompts steer models toward accurate and robust cross-lingual behavior. We propose a unified four-dimensional evaluation framework to assess system prompts in multilingual environments. Through large-scale experiments on five languages, three LLMs, and three benchmarks, we uncover that certain prompt components, such as CoT, emotion, and scenario, correlate with robust multilingual behavior. We develop a prompt optimization framework for multilingual settings and show it can automatically discover prompts that improve all metrics by 5-10%. Finally, we analyze over 10 million reasoning units and find that more performant system prompts induce more structured and consistent reasoning patterns, while reducing unnecessary language-switching. Together, we highlight system prompt optimization as a scalable path to accurate and robust multilingual LLM behavior.

- **SAT-MapIt: A SAT-based Modulo Scheduling Mapper for Coarse Grain Reconfigurable Architectures**
  - 发表日期：2025-12-02 | 推荐度：0.849 | 来源：arXiv
  - DOI：10.23919/DATE56975.2023.10137123
  - 链接：https://arxiv.org/abs/2512.02875v1
  - 摘要：Coarse-Grain Reconfigurable Arrays (CGRAs) are emerging low-power architectures aimed at accelerating compute-intensive application loops. The acceleration that a CGRA can ultimately provide, however, heavily depends on the quality of the mapping, i.e. on how effectively the loop is compiled onto the given platform. State of the Art compilation techniques achieve mapping through modulo scheduling, a strategy which attempts to minimize the II (Iteration Interval) needed to execute a loop, and they do so usually through well known graph algorithms, such as Max-Clique Enumeration.
  We address the mapping problem through a SAT formulation, instead, and thus explore the solution space more effectively than current SoA tools. To formulate the SAT problem, we introduce an ad-hoc schedule called the \textit{kernel mobility schedule} (KMS), which we use in conjunction with the data-flow graph and the architectural information of the CGRA in order to create a set of boolean statements that describe all constraints to be obeyed by the mapping for a given II. We then let the SAT solver efficiently navigate this complex space. As in other SoA techniques, the process is iterative: if a valid mapping does not exist for the given II, the II is increased and a new KMS and set of constraints is generated and solved.
  Our experimental results show that SAT-MapIt obtains better results compared to SoA alternatives in $47.72\%$ of the benchmarks explored: sometimes finding a lower II, and others even finding a valid mapping when none could previously be found.

- **Vessel Network Topology in Molecular Communication: Insights from Experiments and Theory**
  - 发表日期：2025-12-02 | 推荐度：0.849 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02811v1
  - 摘要：The notion of synthetic molecular communication (MC) refers to the transmission of information via signaling molecules and is foreseen to enable innovative medical applications in the human cardiovascular system (CVS). Crucially, the design of such applications requires accurate and experimentally validated channel models that characterize the propagation of signaling molecules, not just in individual blood vessels, but in complex vessel networks (VNs), as prevalent in the CVS. However, experimentally validated models for MC in VNs remain scarce. To address this gap, we propose a novel channel model for MC in complex VN topologies, which captures molecular transport via advection, molecular and turbulent diffusion, as well as adsorption and desorption at the vessel walls. We specialize this model for superparamagnetic iron-oxide nanoparticles (SPIONs) as signaling molecules by introducing a new receiver (RX) model for planar coil inductive sensors, enabling end-to-end experimental validation with a dedicated SPION testbed. Validation covers a range of channel topologies, from single-vessel topologies to branched VNs with multiple paths between transmitter (TX) and RX. Additionally, to quantify how the VN topology impacts signal quality, and inspired by multi-path propagation models in conventional wireless communications, we introduce two metrics, namely molecule delay and multi-path spread. We show that these metrics link the VN structure to molecule dispersion induced by the VN and mediately to the resulting signal-to-noise ratio (SNR) at the RX. The proposed VN structure-SNR link is validated experimentally, demonstrating that the proposed framework can support tasks such as optimal sensor placement in the CVS or the identification of suitable testbed topologies for specific SNR requirements. All experimental data are openly available on Zenodo.

- **On the Performance of Multi-Wavelength Underwater Optical Channels in the Presence of Optical Turbulence**
  - 发表日期：2025-12-02 | 推荐度：0.849 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02913v1
  - 摘要：This paper presents an analysis of the performance of a Gaussian optical beam as it propagates through the turbulent underwater optical channel (UWOC) under the weak turbulence regime, where optical signal experiences significant fading and scattering, all of which can severely degrade communication quality. It is assumed that on-off keying (OOK) modulation with direct detection is utilized to establish a duplex communication link. A multi-wavelength beam approach is implemented to enhance the performance by leveraging the distinct propagation characteristics of different wavelengths. Performance is established in terms of the probability of fade, number of fade per second, mean fade duration, and mean time between fades. The use of multi-wavelength beam is shown to enhance performance by a sizable margin.

- **MICCAI STSR 2025 Challenge: Semi-Supervised Teeth and Pulp Segmentation and CBCT-IOS Registration**
  - 发表日期：2025-12-02 | 推荐度：0.845 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02867v1
  - 摘要：Cone-Beam Computed Tomography (CBCT) and Intraoral Scanning (IOS) are essential for digital dentistry, but annotated data scarcity limits automated solutions for pulp canal segmentation and cross-modal registration. To benchmark semi-supervised learning (SSL) in this domain, we organized the STSR 2025 Challenge at MICCAI 2025, featuring two tasks: (1) semi-supervised segmentation of teeth and pulp canals in CBCT, and (2) semi-supervised rigid registration of CBCT and IOS. We provided 60 labeled and 640 unlabeled IOS samples, plus 30 labeled and 250 unlabeled CBCT scans with varying resolutions and fields of view. The challenge attracted strong community participation, with top teams submitting open-source deep learning-based SSL solutions. For segmentation, leading methods used nnU-Net and Mamba-like State Space Models with pseudo-labeling and consistency regularization, achieving a Dice score of 0.967 and Instance Affinity of 0.738 on the hidden test set. For registration, effective approaches combined PointNetLK with differentiable SVD and geometric augmentation to handle modality gaps; hybrid neural-classical refinement enabled accurate alignment despite limited labels. All data and code are publicly available at https://github.com/ricoleehduu/STS-Challenge-2025 to ensure reproducibility.

- **Model-Based Diagnosis with Multiple Observations: A Unified Approach for C Software and Boolean Circuits**
  - 发表日期：2025-12-02 | 推荐度：0.845 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02898v1
  - 摘要：Debugging is one of the most time-consuming and expensive tasks in software development and circuit design. Several formula-based fault localisation (FBFL) methods have been proposed, but they fail to guarantee a set of diagnoses across all failing tests or may produce redundant diagnoses that are not subset-minimal, particularly for programs/circuits with multiple faults.
  This paper introduces CFaults, a novel fault localisation tool for C software and Boolean circuits with multiple faults. CFaults leverages Model-Based Diagnosis (MBD) with multiple observations and aggregates all failing test cases into a unified Maximum Satisfiability (MaxSAT) formula. Consequently, our method guarantees consistency across observations and simplifies the fault localisation procedure. Experimental results on three benchmark sets, two of C programs, TCAS and C-Pack-IPAs, and one of Boolean circuits, ISCAS85, show that CFaults is faster at localising faults in C software than other FBFL approaches such as BugAssist, SNIPER, and HSD. On the ISCAS85 benchmark, CFaults is generally slower than HSD; however, it localises faults in only 6% fewer circuits, demonstrating that it remains competitive in this domain. Furthermore, CFaults produces only subset-minimal diagnoses of faulty statements, whereas the other approaches tend to enumerate redundant diagnoses (e.g., BugAssist and SNIPER).

- **Qubit Lattice Algorithm Simulations of the Scattering of a Bounded Two Dimensional Electromagnetic Pulse from an Infinite Planar Dielectric Interface**
  - 发表日期：2025-12-02 | 推荐度：0.845 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02856v1
  - 摘要：Qubit lattice algorithm (QLA) simulations are performed for a two-dimensional (2D) spa- tially bounded pulse propagating onto a plane interface between two dielectric slabs. QLA is an initial value scheme that consists of a sequence of unitary collision and streaming operators, with appropriate potential operators, that recover Maxwell equations in inhomogeneous dielec- tric media to second order in the lattice discreteness. For the case of total internal reflection, there is transient energy transfer into the second medium due to the evanescent fields as the Poynting unit vector of the pulse is rotated from its incident to reflected direction. Because of the finite spatial extent of the pulse, a self- consistent Goos-Hanchen-type displacement along the interface is found without imposing any explicit interface boundary conditions on the fields. For normal incidence. the standard Fresnel coefficients are recovered for appropriately averaged QLA fields. Energy is conserved at all times to seven significant figures.

- **BOOM: Beyond Only One Modality KIT's Multimodal Multilingual Lecture Companion**
  - 发表日期：2025-12-02 | 推荐度：0.844 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02817v1
  - 摘要：The globalization of education and rapid growth of online learning have made localizing educational content a critical challenge. Lecture materials are inherently multimodal, combining spoken audio with visual slides, which requires systems capable of processing multiple input modalities. To provide an accessible and complete learning experience, translations must preserve all modalities: text for reading, slides for visual understanding, and speech for auditory learning. We present \textbf{BOOM}, a multimodal multilingual lecture companion that jointly translates lecture audio and slides to produce synchronized outputs across three modalities: translated text, localized slides with preserved visual elements, and synthesized speech. This end-to-end approach enables students to access lectures in their native language while aiming to preserve the original content in its entirety. Our experiments demonstrate that slide-aware transcripts also yield cascading benefits for downstream tasks such as summarization and question answering. We release our Slide Translation code at https://github.com/saikoneru/image-translator and integrate it in Lecture Translator at https://gitlab.kit.edu/kit/isl-ai4lt/lt-middleware/ltpipeline}\footnote{All released code and models are licensed under the MIT License.

- **Bangla Hate Speech Classification with Fine-tuned Transformer Models**
  - 发表日期：2025-12-02 | 推荐度：0.842 | 来源：arXiv
  - DOI：
  - 链接：https://arxiv.org/abs/2512.02845v1
  - 摘要：Hate speech recognition in low-resource lan- guages remains a difficult problem due to in- sufficient datasets, orthographic heterogeneity, and linguistic variety. Bangla is spoken by more than 230 million people of Bangladesh and India (West Bengal). Despite the grow- ing need for automated moderation on social media platforms, Bangla is significantly under- represented in computational resources. In this work, we study Subtask 1A and Subtask 1B of the BLP 2025 Shared Task on hate speech detection. We reproduce the official base- lines (e.g., Majority, Random, Support Vec- tor Machine) and also produce and consider Logistic Regression, Random Forest, and De- cision Tree as baseline methods. We also uti- lized transformer-based models such as Dis- tilBERT, BanglaBERT, m-BERT, and XLM- RoBERTa for hate speech classification. All the transformer-based models outperformed base- line methods for the subtasks, except for Distil- BERT. Among the transformer-based models, BanglaBERT produces the best performance for both subtasks. Despite being smaller in size, BanglaBERT outperforms both m-BERT and XLM-RoBERTa, which suggests language- specific pre-training is very important. Our results highlight the potential and need for pre- trained language models for the low-resource Bangla language.
